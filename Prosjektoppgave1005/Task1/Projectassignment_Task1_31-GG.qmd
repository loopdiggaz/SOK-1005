---
title: "Prosjektoppgave task1"
author: "31"
format: html
editor: visual
---

```{r}
rm(list=ls())
```

```{r}
# Packages for data wrangling. 
suppressPackageStartupMessages({
library(haven)
library(tidyverse)
library(lubridate)})
```

```{r}
category <- c("Analgesics","Bath Soap","Beer","Bottled Juices","Cereals",
              "Cheeses","Cigarettes","Cookies","Crackers","Canned Soup",
              "Dish Detergent","Front-end-candies","Frozen Dinners","Frozen Entrees",
              "Frozen Juices","Fabric Softeners","Grooming Products","Laundry Detergents",
              "Oatmeal","Paper Towels","Soft Drinks","Shampoos","Snack Crackers",
              "Soaps","Toothbrushes","Canned Tuna","Toothpastes","Bathroom Tissues")

letter2number <- function(x) {utf8ToInt(x) - utf8ToInt("A") + 1L}
seed_number <- sum(letter2number("Gustav"))
set.seed(seed_number)
sample(category, 1)

```

In this project assignment for the class 1005 - datavitenskap for Ã¸konomer, i have used data from the James M. Kilts Center, University of Chicago Booth School of Business. The task takes use of four datasets. The coustomer count file, and the store-level demographic file can be downloaded from: <https://www.chicagobooth.edu/research/kilts/datasets/dominicks>.

The other two files used contains data on laundry detergents (UPCs and Movements). These files can downloaded directly from the links below.

UPC file:

<https://www.chicagobooth.edu/-/media/enterprise/centers/kilts/datasets/dominicks-dataset/upc_csv-files/upclnd.csv?la=en&hash=99A99F1AF79BB754643A1610C67ABA0E4AFAFAB5>

Movement file:

<https://www.chicagobooth.edu/-/media/enterprise/centers/kilts/datasets/dominicks-dataset/movement_csv-files/wlnd.zip?la=en&hash=BFC61F369725363F7F8360CA7D34C1731C985BA9>

Once the files are downloaded locally, u can read them by inserting the file paths in the code block under.

More infomation on the data can be found in the data manual:

<https://www.chicagobooth.edu/-/media/enterprise/centers/kilts/datasets/dominicks-dataset/dominicks-manual-and-codebook_kiltscenter>

```{r}
# Customer count file. 
ccount <- read_dta("C://Users/gusta/OneDrive/Skrivebord/ccount.dta") 

# Store demographic file. 
demo <- read_dta("C://Users/gusta/OneDrive/Skrivebord/demo.dta") 

# Laundry detergent upc file. 
upc_ld = read.csv("C://Users/gusta/OneDrive/Skrivebord/upclnd.csv",sep=',') 
# Laundry detergent movement file. 
mvm_ld = read.csv("C://Users/gusta/OneDrive/Skrivebord/wlnd.csv",sep=',')
```

```{r}
# Run this for different detergent UPCs:

# unique(upc_ld$DESCRIP)
```

We can see there is a lot of different UPCs for detergents. In the code block below i have merged all these UPCs into one brand category. I have also used a filter to remove detergent products that are under 60 ounces in size, this made the code run a lot faster.

```{r}
brands <- paste(c("SURF", "WISK", "SOLO", "ERA" , "TIDE"), collapse = "|") # Picking brands for data analysis. 

upc_ld <- upc_ld %>%
  filter(grepl(brands,DESCRIP)) %>%  # Filter for the brands. 
  mutate(BRAND = str_extract(DESCRIP, brands)) %>%  # Adding brands as column.
  separate(col = SIZE, into = c("SIZE","DEL"), sep = " ") %>%  # Separating size column. 
  filter(SIZE > 60) # Filter for size of detergent products. 
```

Some info on the data:

1\. UPC: This is the key to use while merging with upc file.

2\. Price, Quantity and Movement: DFF will sometimes bundle products (E.g., 3 cans of tomato soup for \$2). In such occasion, the 'qty' variable will indicate the size of the bundle (E.g., 3), the price will reflect the total price of the bundle (E.g., \$2), but move will reflect the number of actual item sold, not the number of bundles.

Hence, to compute total dollar sales, one must do the following calculation: Sales = Price \* Move / Qty.

3\. Profit: This variable indicates the gross margin in percent that DFF makes on the sale of the UPC. A profit of 25.3 means that DFF makes 25.3 cents on the dollar for each item sold. This yields a cost of good sold of 74.7 cents.

4\. Sales: This variable indicates whether the product was sold on a promotion that week. A code of 'B' indicates a Bonus Buy, 'C' indicates a Coupon, 'S' indicate a simple price reduction. Unfortunately, this variable is not set by DFF on consistent basis (I.e., if the variable is set it indicates a promotion, if it is not set, there might still be a promotion that week).

5\. OK: This is a flag set by us to indicate that the data for that week are suspect. We do not use flagged data in our analysis."

Source: Dominick's Data Manual.

```{r}
#|message: false
mvmupc <- left_join(upc_ld,mvm_ld, by=c('UPC')) # Left join by key. 

mvmupc <- mvmupc %>% 
  filter(OK > 0) # Removing trash data. 1 is for valid data 0 is for trash (see data manual). 

# Adding sales column in dollars. 
mvmupc <- mvmupc %>%
  group_by(WEEK,STORE,UPC) %>% # Group by keys. 
  mutate(SALES = PRICE*MOVE/QTY) %>% # Formula as stated in data manual. 
  filter(SALES > 0) # Filter for sales over 0. 

mvmupc <- mvmupc %>% # Relocating columns for tidiness.
  relocate(SALES, .before = PROFIT) %>% 
  relocate(WEEK, .before = COM_CODE)  %>% 
  relocate(STORE, .before = COM_CODE)

mvmupc <- mvmupc %>%  # Filter for weeks in 1990
  filter(between(WEEK,16,68))

mvmupc <- mvmupc %>% # Removing some columns i dont need.
  select(-PRICE_HEX,-PROFIT_HEX,-OK,-COM_CODE,-DEL,-NITEM,-CASE)  
```

```{r}
#|message: false
mvmupc <- mvmupc %>% # Calculating some data i need for analysis. 
  group_by(STORE, WEEK, BRAND) %>% # Group by keys. 
  summarise(MOVE_SUM = sum(MOVE), # The sum of units sold. 
            AVG_PROFIT = (mean(PROFIT)/100), # The average profit in percent of dollar per unit sold. 
            AVG_PRICE = mean(PRICE), # The average price of the products. 
            SUM_SALES = sum(SALES)) # The sum of sales in dollars. 
```

```{r}
colnames(ccount)
```

```{r}
ccount <- na.omit(ccount) # Removing missing data. 

ccount$date <- as.Date(ccount$date, "%y%m%d") # Date variable.  

ccount <- ccount %>% 
  mutate(date = as.Date(date)) %>% # Convert to date. 
  filter(between(date, as.Date('1990-01-01'), as.Date('1990-12-31'))) %>% # Filter for year. 
  relocate("week", .before = store) %>% # Relocate for tidiness. 
  rename(WEEK = week) %>% # Renaming for merge. 
  rename(STORE = store)
```

```{r}
# Using the colnames() function to get var names. 

# Aggregate by week and store
ccount <- ccount %>%   
  group_by(WEEK,STORE) %>% 
  summarise_at(.vars = c("grocery","dairy","frozen","bottle","mvpclub","groccoup","meat","meatfroz","meatcoup","fish","fishcoup", "promo","promcoup", "produce",  "bulk","saladbar","prodcoup","bulkcoup","salcoup","floral","florcoup", "deli", "deliself", "deliexpr","convfood", "cheese","delicoup","bakery" , "pharmacy", "pharcoup", "gm" , "jewelry", "cosmetic","haba","gmcoup",   "camera" ,  "photofin" ,"video"  , "videoren", "vidcoup" , "beer" , "wine" ,"spirits" , "miscscp" , "mancoup" , "custcoun", "ftgchin" , "ftgccoup","ftgital" , "ftgicoup" ,"daircoup" ,"frozcoup", "habacoup" ,"photcoup" ,"cosmcoup", "ssdelicp" ,"bakcoup" , "liqcoup"), .funs = sum) 
```

For a better overview i have printed the number of store observations in both the merged movement file and the aggregated ccount file.

```{r}
unique(mvmupc$STORE)
```

```{r}
unique(ccount$STORE)
```

We can now see that the ccount includes more data on stores. When i merge the data there will be some missing values on store observations.

```{r}
ccount_mvmupc <- left_join(mvmupc, ccount, by= c("WEEK","STORE"))

ccount_mvmupc <- ccount_mvmupc %>% # Removing duplicated rows (if any).  
  distinct()
```

```{r}
demo <- demo %>% # Removing column with missing values. 
  select(-gini)

demo <- demo %>%  # Renaming for merge. 
  rename(STORE = store) 

sum(is.na(demo))

demo <- demo %>% 
  select(-name,-zip,-zone,-lat,-long,-weekvol)

# We can see there is a lot of missing values in the demo data.
```

```{r}
df <- left_join(ccount_mvmupc,demo,by=c('STORE')) # Left join by key.

df <- df %>% # Relocateing for tidiness. 
  relocate(city, .before = BRAND) %>% 
  relocate(age9, .before = grocery) %>% 
  relocate(age60, .before = grocery) %>% 
  relocate(hsizeavg, .before = grocery) %>% 
  relocate(unemp, .before = grocery) %>% 
  relocate(wrkch, .before = grocery) 
  
# Weeks start at 16, to make variable start at 1 i substract by 15.
df <- df %>% 
  mutate(WEEK = WEEK - 15)

df <- df %>% 
  distinct() # Removing duplicated rows (if any). 

df <- df[, 1:115] # Picking columns i need. 

df <- df[,-29:-59] # Deleting columns i dont need. 
df <- df[,-29:-43]
```

```{r}
write_csv(df, "df.csv") # Writing final df as csv file for sales report. 
```
